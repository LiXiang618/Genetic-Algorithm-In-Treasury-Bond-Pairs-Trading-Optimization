{
    "contents" : "#####################################################\n# File: q3-TD-learning.R\n# Author: Antoine Sachet\n# Github: github.com/antoine-sachet/easy21-RL-project\n# Date: 04/2015\n#####################################################\n\n# This file contains the functions to perform Temporal Difference reinforcement learning.\n# I use the SARSA algorithm for on-policy control,\n# implemented using the backward-view (eligibility traces).\n#\n# The helper function epsgreedy is also defined.\n#\n# Note that the function sarsa() requires some functions from q1-step.R.\n# Please run q1-step.R prior to running this file.\n\nload.library <- function(package_name) {\n  package_name <- as.character(match.call()[[2]])\n  if (!require(package_name, character.only = T)) {\n    install.packages(package_name)\n    require(package_name)\n  }\n}\n####### FUNCTION DEFINITIONS #######\n\nload.library(\"plyr\")\nload.library(\"foreach\")\n\nperiodFeatures <- function(period) {\n  return (c(\n    (period>=100&period<=110),\n    (period>110&period<=120),\n    (period>120&period<=130),\n    (period>130&period<=140),\n    (period>140&period<=150),\n    (period>150&period<=160),\n    (period>160&period<=170),\n    (period>170&period<=180),\n    (period>180&period<=190),\n    (period>190&period<=200)))\n}\n\n\nthesholdFeatures <- function(theshold) {\n  return (c(\n    (theshold>=2.0&theshold<=2.2),\n    (theshold>2.2 & theshold<=2.4),\n    (theshold>2.4&theshold<=2.6),\n    (theshold>2.6 & theshold<=2.8),\n    (theshold>2.8&theshold<=3.0)))\n}\n\n# INPUT\n#   playerState: sum of the player, integer between 1 and 21\n# OUTPUT\n#   boolean vector coding the player card interval on 6 bits\n\nstoplossFeatures <- function(stoploss) {\n  return (c(\n    (stoploss>=3.0&stoploss<=3.1),\n    (stoploss>3.1&stoploss<=3.2),\n    (stoploss>3.2 & stoploss<=3.3),\n    (stoploss>3.3&stoploss<=3.4),\n    (stoploss>3.4 & stoploss<=3.5)\n    ))\n}\n\n\n# INPUTS\n#   s: state (as defined in q1-step.R)\n#   a: action, integer: HIT(1) or STICK(2)\n# returns a binary vector of length 36 representing the features\nphi <- function(s, a) {\n  tmp <- array(0, dim=c(10,5,5)) #empty array of dim 10*5*5\n  tmp[periodFeatures(a[1]),\n      thesholdFeatures(a[2]),\n      stoplossFeatures(a[3])] <- 1 #putting one where a feature is on\n  return(as.vector(tmp)) #returning 'vectorized' (1-dim) array\n}\n\n# INPUTS\n#   s: state (as defined in q1-step.R)\n#   Q: action-value function, that is an array of dim: (10, 21, 2)\n#   eps: numeric value for epsilon\n# OUTPUT\n# action to take following an epsilong-greedy policy\n# 1 is HIT and 2 is STICK (as defined in q1-step.R)\n# a[1] period a[2] theshold a[3] stoploss\nepsgreedy <- function(s,a, Q, eps) {\n  if (runif(1) < eps)\n    return(c(sample(seq(100,200, by = 10),1),sample(seq(2, 3, by = 0.1),1),sample(seq(3, 3.5, by = 0.1),1))) # random action taken with eps probability\n  else\n    return(which.max(Q(s,a))) # else action maximizing Q\n}\n\n\n# INPUTS\n#   lambda: lambda parameter for SARSA\n#       numeric between 0 and 1\n#       quantifies the weighting of the steps within an episode\n#   gamma: dicounting factor\n#       default to 1\n#   Q: action-value \"function\",\n#       that is an array of dim: (10, 21, 2)\n#       will be an array of 0 if not provided\n#   w: parameter vector of length 500\n#     Q(s,a) is approximated by phi*w where phi is detailed above\n#   nb.episode: number of episode to play\n#   N0: offset for N.\n#       At each episode, an epsilon-greedy action is taken with\n#       eps = N0/(total+N0) where total is the total number of times\n#       this state has been visited.\n# OUTPUT\n#   list of:\n#     Q: updated action-value function\n#     N: updated counter of state-action visits\nsarsa <-\n  function(lambda, gamma=1, w=NULL, nb.episode=1, eps=0.05, step.size=0.01) {\n    \n    if (is.null(w))\n    w <- array(0,dim=250)\n\n    Q <- function(s,a) as.vector(phi(s,a) %*% w)\n\n    policy <- function(s) {\n      epsgreedy(s, Q, eps)\n    }\n\n    for (i in 1:nb.episode) {\n      s <- s.ini()\n      # choosing initial action a\n      a <- policy(s)\n      r <- 0L\n      # eligibility trace\n       e <- array(0L, dim=250)\n\n      # s[3] is the \"terminal state\" flag\n      # s[3]==1 means the game is over\n      while (s[3] == 0L) {\n       \n        # performing step\n        tmp <- step(s, a)\n        s2 <- tmp[[1]]\n        r <- r + tmp[[2]]\n\n        # if s2 is terminal\n        if (s2[3] == 0) {\n          # choosing new action\n          a2 <- policy(s2)\n          # sarsa backward view formula with estimated return r+gamma*Q2\n          delta <- r + gamma *Q(s2,a2) - Q(s,a)\n        } else {\n          # sarsa backward view formula, with now known return r\n          #计算全部的R\n          delta <- r - Q(s,a)\n          a2 <- 0L\n        }\n        ind <- which(e > 0)\n        # updating Q\n        w <- w + step.size*delta*e\n        e <- gamma * lambda * e\n        s <- s2\n        a <- a2\n      }\n    }\n    return(w)\n  }\n\n\n######## COMPUTING Q WITH SARSA #########\n\n#start from 100 day\ns.ini <- function () {\n  return ( c(0L,0L, 0L))\n}\n\nMSE <- foreach(1:10, .combine = rbind) %do% {\n  # computing Q for lambda from 0 to 1\n  lambdas <- seq(0, 1, 0.1)\n  Qsarsa <- llply(\n    lambdas, .fun = function(lambda) {\n      sarsa(lambda, nb.episode = 1000)[[1]]\n    }\n  )\n\n  # computing MSE between sarsa's Q and montecarlo's Q\n  MSE <- laply(\n    Qsarsa, .fun = function(Q) {\n      mean((Q - QMC) ** 2)\n    }\n  )\n}\n\n\n\n\n\n\n\n###################################################################################################################\n\n# plotting the MSE vs lambda\nload.library(\"ggplot2\")\nload.library(\"tseries\")\nload.library(\"xts\")\nload.library(\"PerformanceAnalytics\")\nload.library(\"assertthat\")\nsource(\"Cointegration.R\")\nsource(\"PairTrading.R\")\nsource(\"Signal.R\")\n#source(\"Setp.R\")\n#load sample stock price data\nload(\"stock.price.rda\")\nprice.pair <- stock.price[, 1:2][\"2006-1-03::\"]\n\n\nday <<- 190\nsignals <<- xts(array(NA, dim = nrow(price.pair)), order.by = index(price.pair))\npair.zscore <<- xts(array(NA, dim = nrow((price.pair))), order.by = index(price.pair))\nnum.price <- nrow(price.pair)\nwhole.weight <<- xts(data.frame(p1=rep(0, num.price), p2=rep(0, num.price)), order.by = index(price.pair))\n\n#test setp\ns <- s.ini()\na <- c(120, 2.0, 4.0, 130)\nwhile (s[3] == 0L) {\n  # performing step\n  tmp <- Setp(price.pair, s, a)\n  s <- tmp[2:4]\n  print(c(tmp[1], s[3], day-1, signals[day-1], pair.zscore[day-1]))\n}\nprint(c(s[3], day-1, signals[day-1], pair.zscore[day-1]))\n\nsignals <- na.omit(na.locf(signals))\nPlotWithSignal(pair.zscore, signals, a[2], 0, a[3])\n\nprice.return <- Return.calculate(price.pair)\nportfolio.return <- Return.portfolio(na.omit(price.return), weights = lag(whole.weight), geometric = F)\ncharts.PerformanceSummary(portfolio.return)\n\n###################################################################################################################\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndf <-\n  data.frame(\n    lambda = lambdas, mse = colMeans(MSE), se = aaply(MSE, .margins = 2, sd)\n  )\nggplot(df) + geom_point(aes(x = lambda, y = mse)) +\n  geom_errorbar(aes(\n    x = lambda, y = mse, ymin = mse - se, ymax = mse + se\n  ))\n\n# computing MSE at every step for lambda=1\nQ <- NULL\nN <- NULL\nmse <- times(1000) %do% {\n  res <- sarsa(\n    lambda = 1, Q = Q, N = N, nb.episode = 1\n  )\n  Q <- res$Q; N <- res$N\n  mean((Q - QMC) ** 2)\n  }\nplot(mse)\n\n# computing MSE at every step for lambda=0\nQ <- NULL\nN <- NULL\nmse <- times(1000) %do% {\n  res <- sarsa(\n    lambda = 0, Q = Q, N = N, nb.episode = 1\n  )\n  Q <- res$Q; N <- res$N\n  mean((Q - QMC) ** 2)\n}\nplot(mse)\n",
    "created" : 1456583353504.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4088104095",
    "id" : "3DC20024",
    "lastKnownWriteTime" : 1456576692,
    "path" : "D:/百度云/My Box Files/SAIF/论文/2016/Code/PairsTradingForRLWK0.2/Sarsa.R",
    "project_path" : "Sarsa.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_source"
}